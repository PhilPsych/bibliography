<!DOCTYPE html>
<html lang="en">
<head>
	<link href="bibliography.css" rel="stylesheet" type="text/css">
	<link href="https://fonts.googleapis.com/css?family=Lato|Work+Sans" rel="stylesheet">
	<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
	<script src="editPage.js">
	</script>
	<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js">
	</script>
	<title>Bibliography - K. Dewsnap</title>
</head>
<body onload="dateAndEdits()">
	<div id="main">
		<div id="sidebar">
			<p><a href="#vessonen">Vessonen, E. (2017).</a> Psychometrics versus Representational Theory of Measurement.</p>
			<hr>
			<p><a href="#humphry">Humphry, S. M. (2017).</a> Psychological measurement: Theory, paradoxes, and prototypes.</p>
			<hr>
			<p><a href="#mcclimans">McClimans, L. (2017).</a> Health Measurement, Industry, and Science.</p>
			<hr>
			<p><a href="#kaminski">Kaminski, A. (2017).</a> Measuring Intelligence effectively: Psychometrics from a Philosophy of Technology Perspective.</p>
			<hr>
			<p><a href="#michell">Michell, J. (2008).</a> Is Psychometrics Pathological Science?</p>
			<hr>
			<p><a href="#alexandrova">Alexandrova, A. (2017).</a> A Philosophy for the Science of Well-Being</p>
			<hr>
			<p><a href="#angner">Angner, E. (2010).</a> Current Trends in Welfare Measurement.</p>
			<hr>
			<p><a href="#borsboom">Borsboom, D. &amp; Mellenbergh, G (2004).</a> Why Psychometrics is not Pathological</p>
			<hr>
		</div><!--sidebar-->
		<div id="content">
			<div id="header">
				<h1>Bibliography</h1>
				<h3 id="lastup">x</h3><button id="editToggle" onclick="editButton()">Edit</button> <button onclick="download()">Download Edits</button>
				<hr>
			</div><!--header-->
			<div id="material">
				<div class="head">
					<div class="bib">
						<h4 id="vessonen">Vessonen, E. (2017). Psychometrics versus Representational Theory of Measurement. <i>Philosophy of the Social Sciences, 47</i> (4-5): 330-350. <a class="paper" href="http://journals.sagepub.com/doi/abs/10.1177/0048393117705299" target="_blank">doi:10.1177/0048393117705299</a></h4>
					</div>
					<div class="buttons">
                        <a href="downloads/vessonen2017.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">Vessonen's paper argues that it is possible to simultaneously endorse both psychometrics and the representational theory of measurement (RTM). She first establishes her position by arguing that RTM and psychometrics have distinct sources of validity. RTM measurements posses representational interpretability, which is the mirroring of the measured construct's empirical structure to the numeric structure of the instrument of measure. Psychometric measures must have procedural validity, which is present when multiple determinations of the target construct form theoretical expectations that cohere with the measurment's results. Vessonen then iterates that RTM does not address measurement's need for procedural validity – RTM says nothing about how to build a construct-valid measurement procedure. Conversely, psychometricians tend to assume the validity of the scales they use, rather than establishing representational interpretability by mirroring their scales against the empirical relationships within the construct. As both theories are partial approaches that deal with different measurement conditions, Vessonen argues that embracing both theories simultaneously is not only possible but can yield fruitful results for researchers.</p>
				<p class="content" contenteditable="false">The paper is built as a charitable critique of <a href="#angner">Angner (2011)</a>, that argues for the incompatibility between RTM and psychometrics. Substantial definitions are given to each term by the author at its introduction. Similar to <a href="#humphry">Humphry (2017)</a>, the author believes that RTM is an incomplete theory of measurement. Interestingly, this author establishes psychometrics as its own measurement theory, contradictory to Borsboom (2005).</p>
				<hr>
                <div class="head">
					<div class="bib">
						<h4 id="humphry">Humphry, S. M. (2017). Psychological measurement: Theory, paradoxes, and prototypes. <i>Theory &amp; Psychology 27</i>(3):407-418. <a class="paper" href="http://journals.sagepub.com/doi/abs/10.1177/0959354317699099" target="_blank">doi:10.1177/0959354317699099</a></h4>
					</div>
					<div class="buttons">
                        <a href="downloads/humphry2017.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">This article is a critique of the improper use of the term 'theory' by different psychological measurement methodologies. Humphry first defines theory as the theoretical framework used to explain specific phenomena. With this definition established, Humphries critiques item response theory (IRT) and the representational theory of measurement (RTM) for not being true 'theories' – these models only prescribe which strict conditions are required for measurement, and does not explain how scientific theories can support said measure. The author later establishes that as IRT and RTM do not account for measurement's need to be supported by 'substantive theory', these models are partial and quasi-empirical. He ends by establishing a substantive theory of measurement, and warns psychometricians that psychological measurement cannot be possible unless psychologists develop substantive theories that can be used to develop well-defined units of measurement.</p>
				<p class="content" contenteditable="false">The author structures his article as a critique of Joel Michell's "The Rasch Paradox, Conjoint Measurement and Psychometrics" (2014) (which critiqued Humphry's earlier work) as well as strongly supporting RTM as a complete theory. Humphry uses the historical defintion of the metre as a certain number of wavelengths of a specific frequency of light to demonstrate how substantive theories can be useful in building methods of measurement. The author does not define some of the the key terms he uses, such as RTM, IRT, and Rasch models.</p>
				<hr>
                <div class="head">
					<div class="bib">
						<h4 id="mcclimans">McClimans, L. (2017). Health Measurement, Industry, and Science. <i>Philosophical Issues in Pharmaceutics: Development, Dispensing, and Use.</i> (pp. 93-105). Dordrecht: Springer Netherlands.</h4>
					</div>
					<div class="buttons">
                        <a href="downloads/humphry2017.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
                        <a href="https://link.springer.com/chapter/10.1007/978-94-024-0979-6_6/fulltext.html" class="button" target="_blank"><i class="material-icons">link</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">The paper criticises the metrological foundations of Patient-reported outcome measures (PROMs) and offers suggestions that address her critiques. The author starts by claiming that, as PROMs are based on classical test theory (CTT), PROMs lack a theory of measurement interaction that demonstrates the relationship between the target construct and the instrument of measure (e.g.: a questionnaire). This leads to problems with validity, interpretability, and responsiveness. Consequently, McClimans suggests that psychometricians exercise Rasch methodology to build a theory of measurement interaction. Rasch does this by creating a mathematical model that builds empirical relationships between items and subjects. Although McClimans does believe that PROMs can be improved with Rasch methodologies, she also warns that one should apply Rasch models with strong theoretical guidance to build adequate sensitivity in the model.</p>
                <p class="content" contenteditable="false">McClimans defines Rasch methodology similarly to how Borsboom (2005) defines the representational measurement model. Her critique of CTT is congruent with Vesonnen's critique of Psychometrics. Namely, both models lack a justification for their use of an integer scale to represent their data. McClimans states a belief similar to <a href="#vessonen">Vesonnen (2017)</a>, and <a href="#humphry">Humphry (2017)</a>, saying that theoretically established units of change are necessary in order to build a quantitative scale - something that both CTT and psychometrics do not do.</p>
				<hr>
                <div class="head">
					<div class="bib">
                        <h4 id="kaminski">Kaminski, A. (2017). Measuring Intelligence effectively: Psychometrics from a Philosophy of Technology Perspective. In A. Nordmann &amp; N. Moeßner (Eds.), <i>Reasoning in Measurement</i> (pp. 146-157). London: Routledge.</h4>
					</div>
					<div class="buttons">
                        <a href="downloads/kaminski2017.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">Kaminski's paper is a critique of the philosophy of science's treatment of psychometrics and argues that they should also focus on justifying why the measurement has seen so much technical success. Kaminski first starts his argument by highlighting that, no matter the critique of psychometrics, each critique fails to recognise that psychometrics has had useful social consequences. The author then suggests that comparisons between classical measurements and mental measurements fail to recognise that applications of psychometrics involve a subject that is aware of its own measurement. This explains psychometrics' success as a technical application; psychometrics are tools that create self-relation in a subject, which has great personal and social consequences. The importance of self-relation is shown by examining psychometrics as a direct cause of the Lynn-Flynn Effect.</p>
				<p class="content" contenteditable="false">This paper strongly suggests that an approach from the philosophy of science is insufficient to build a charitable critique of psychometrics - one must also approach it from a philosophy of technological perspective. This implies that the critique that psychometrics offers an incomplete model of measurement (see: <a href="#vessonen">Vessonen (2017)</a>, <a href="#mcclimans">McClimans (2017)</a>) should be considered alongside evidence that demonstrates the social success of psychometrics. Further pieces that criticise psychometrics from the philosophy of technology would be an excellent supplement to this piece.</p>
				<hr>
                <div class="head">
					<div class="bib">
						<h4 id="michell">Michell, J. (2008). Is Psychometrics Pathological Science? <i>Measurement: Interdisciplinary Research and Perspectives 6</i> (1-2), 7-24. <a class="paper" href="http://statmath.wu.ac.at/courses/r-se-mbr/dl/Michell_Psychometrics_Pathology_2008.pdf" target="_blank">doi:10.1080/15366360802035489</a></p>
					</div>
					<div class="buttons">
                        <a href="downloads/michell2008.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">This paper is an effort to establish psychometrics as pathological science. The author first defines the pathology of science as the collective failure of a field to recognise its own prejudice that ultimately prevents true science from taking place. Psychometrics is considered pathological as it refuses to recognise that it assumes that mental qualities are quantitative. The author suggests that this pathology was created out of ideological and economic interests to make psychology a 'valid science'. The paper also critiques more modern attempts to remove the pathology from psychometrics, such as the item response model (ITM), as it too ultimately ignores that the data produced by this model is ordinal, and not quantitative. The paper ends with the author suggesting what steps would be necessary to prove that mental measures provide quantitative (and not just ordinal) information, which would 'depathologise' the rest of the measurement field.</p>
				<p class="content" contenteditable="false">This paper is a destructive critique of psychometrics, with Michell calling it a 'quasi-empirical' field. This critique can be found in constructive forms (see <a href="#vessonen">Vessonen (2017)</a> and <a href="#kaminski">Kaminski (2017)</a>). This suggests that psychometrics should be not be viewed as a complete model of measurement, as it does not rely on empirical evidence in order to establish itself as a valid measurment model.</p>
				<hr>
                <div class="head">
					<div class="bib">
						<h4 id="alexandrova">Alexandrova, A. (2017). Is Well-Being Measurable? In <i>A Philosophy for the Science of Well-Being</i>. New York: Oxford University Press.</h4>
					</div>
					<div class="buttons">
                        <a href="downloads/alexandrova2017.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
                        <a href="http://www.oxfordscholarship.com/view/10.1093/oso/9780199300518.001.0001/oso-9780199300518-chapter-5" class="button"><i class="material-icons" target="_blank">link</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">This chapter argues that the measurement of well-being is possible, even though well-being cannot be measured on an individual level. This article defines well-being as an ‘inclusive good’ that is influenced by a collection of ‘relevant goods’ (e.g. happiness, positive relationships, etc.). As an individuals’ well-being is self-defined, the well-being of individuals is heterogenous, and is impractical to be measured by one measure (i.e. one questionnaire). However, more generalised types of well-being, such as the “well-being of kinds [of individuals]”, can be measured. This is because: (1) by constraining the definition of well-being to mean a certain collection of relative goods that pertain to a kind, its measurement becomes less heterogenous, and; (2) as the relative goods that make up well-being are measurable constructs, a measure of well-being can be compared against said constructs, giving the measure construct validity.</p>
				<p class="content" contenteditable="false">The author is a variantist – she believes that measured constructs can vary in substance and focus. This view makes (1) possible; variantism supports the belief that there are different forms of well-being. The author also claims that construct validity makes psychometrics a valid form of measurement, similarly to how representational theory makes physical measurement valid.</p>
				<hr>
                <div class="head">
					<div class="bib">
						<h4 id="angner">Angner, E. (2010). Current Trends in Welfare Measurement. In J. B. Davis &amp; D. W. Hands (Eds.), <i>The Elgar Companion to Recent Economic Methodology</i>: Edward Elgar Publishing.</h4>
					</div>
					<div class="buttons">
                        <a href="downloads/angner2010.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
                        <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1680053#" class="button" target="_blank"><i class="material-icons">link</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">Angner’s paper argues that, as subjective measures of well-being become more popular with policy makers and economists, the methodology of well-being measurement is shifting from a measurement-theoretic (i.e. representational) approach to a psychometric approach. The paper first establishes that ‘orthodox economic measurements’ (e.g. measures of GDP, surplus/deficit, etc.) rely on measurement-theoretical models, which creates a homomorphism that links observable items (such as economic choices and states) to a transitive and associative numeric scale. The author then compares this to the measurement of subjective well-being, such as measures of a population's overall happiness. These measures use a psychometric approach, which makes the measurment of an unobservable latent variable (like well-being) possible. The author completes his paper by stating that, as the two approaches treat data and evidence in fundamentally different ways, the two approaches are incompatible.</p>
				<p class="content" contenteditable="false">This paper precedes and motivates the arguments made in <a href="#vessonen">Vessonen (2017)</a>. While both authors agree that a measure made using one approach cannot be valid in the other, Vessonen argues that this does not mean the simultaneous endorsement of the two approaches is inconsistent. This paper also compliments <a href="#kaminski">Kaminski (2017)</a>, as the two both address the socioeconomic usefulness of the psychometric approach.</p>
				<hr>
		<div class="head">
					<div class="bib">
                        <h4 id="borsboom">Borsboom, D., &amp; Mellenbergh, G. J. (2004). Why Psychometrics is Not Pathological: A Comment on Michell. <i>Theory &amp; Psychology, 14</i>(1), 105-120. <a href="http://journals.sagepub.com/doi/abs/10.1177/0959354304040200#articleCitationDownloadContainer" target="_blank">doi:10.1177/0959354304040200</a><p></h4>
					</div>
					<div class="buttons">
                        <a href="downloads/borsboom2004.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">Borsboom and Mellenbergh’s paper argues that Michell’s critiques of psychometrics in his 2008 paper “Is Psychometrics a Pathological Science” are not relevant to item-response theories of measurement (IRTs). As psychological tests can only provide probabilistic data, the authors state that this data cannot be analysed with a deterministic model, such as the fundamental/representational theory of measurement. To conduct measurement with probabilistic data, psychometricians loosen this fundamental theory by hypothesising that a latent variable (i.e. the target construct) is the main cause of variation between test scores. The introduction of a latent variable allows for an item-response function to be built by studying the effects of attribute factors and item factors, ultimately making measurement possible.</p>
				<p class="content" contenteditable="false">The authors believe that failed IRFs are falsified because they rely on false assumptions. As a latent hypothesis is one of the assumptions that an IRT model makes, and assumptions are never falsified in isolation (as per the Quine-Duhem thesis), the authors believe that psychometricians do not empirically test the latent hypothesis because it is impossible to test, not because it is “blindly accepted as true” as <a href="michell">Michell (2008)</a> suggests. The authors concede that Michell’s critiques are applicable to classical test theory, as the classical test theory is not a model, but a tautology.</p>
			</div><!--material-->
		</div><!--content-->
	</div><!--main->
<!=== Templates
 For Sidebar:
  <p><a href="#authorname">AUTHOR NAME(YEAR).</a> "TITLE"</p>
  <hr>
 For Main:

-->
</body>
</html>
	  
